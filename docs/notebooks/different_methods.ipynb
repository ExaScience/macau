{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying different Matrix Factorzation Methods\n",
    "\n",
    "In this notebook we will try out several MF methods supported by SMURFF.\n",
    "\n",
    "### Downloading the files\n",
    "\n",
    "As in the previous example we download the ChemBL dataset. The resulting IC50 matrix is a compound x protein matrix, split into train and test. The ECFP matrix has features as side information on the compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smurff\n",
    "\n",
    "ic50_train, ic50_test, ecfp = smurff.download_chembl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization without Side Information\n",
    "\n",
    "As a first example we can run SMURFF without side information. The method used here is BPMF.\n",
    "\n",
    "Input matrix for `Y` is a sparse scipy matrix (either coo_matrix, csr_matrix or csc_matrix). The test matrix\n",
    "`Ytest` also needs to ne sparse matrix of the same size as `Y`. Here we have used burn-in of 20 samples for the Gibbs sampler and then collected 80 samples from the model. We use 16 latent dimensions in the model.\n",
    "\n",
    "For good results you will need to run more sampling and burnin iterations (>= 1000) and maybe more latent dimensions.\n",
    "\n",
    "We create a session, and the `run` method returns the predictions of the `Ytest` matrix. `predictions` is a list of of type `Prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = smurff.BPMFSession(\n",
    "                       Ytrain     = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       num_latent = 16,\n",
    "                       burnin     = 20,\n",
    "                       nsamples   = 80,\n",
    "                       verbose    = 0,)\n",
    "\n",
    "predictions = session.run()\n",
    "print(\"First prediction element: \", predictions[0])\n",
    "\n",
    "rmse = smurff.calc_rmse(predictions)\n",
    "print(\"RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Factorization with Side Information\n",
    "\n",
    "If we want to use the compound features we can use the Macau algorithm.\n",
    "\n",
    "The parameter `side_info = [ecfp, None]` sets the side information for rows and columns, respectively. In this example we only use side information for the compounds (rows of the matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = smurff.MacauSession(\n",
    "                       Ytrain     = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       side_info  = [ecfp, None],\n",
    "                       num_latent = 16,\n",
    "                       burnin     = 40,\n",
    "                       nsamples   = 100).run()\n",
    "\n",
    "smurff.calc_rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate sampler\n",
    "\n",
    "SMURFF also includes an option to use a *very fast* univariate sampler, i.e., instead of sampling blocks of variables jointly it samples each individually. An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = smurff.MacauSession(\n",
    "                       Ytrain     = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       side_info  = [ecfp, None],\n",
    "                       univariate = True,\n",
    "                       num_latent = 32,\n",
    "                       burnin     = 500,\n",
    "                       nsamples   = 3500,\n",
    "                       verbose    = 1,).run()\n",
    "smurff.calc_rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using it we recommend using larger values for `burnin` and `nsamples`, because the univariate sampler mixes slower than the blocked sampler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tensor Factorization\n",
    "\n",
    "SMURFF also supports tensor factorization with and without side information on any of the modes. Tensor can be thought as generalization of matrix to relations with more than two items. For example 3-tensor of `drug x cell x gene` could express the effect of a drug on the given cell and gene. In this case the prediction for the element `Yhat[i,j,k]`* is given by\n",
    "\n",
    "$$ \\hat{Y}_{ijk} = \\sum_{d=1}^{D}u^{(1)}_{d,i}u^{(2)}_{d,j}u^{(3)}_{d,k} + mean $$\n",
    "\n",
    "Visually the model can be represented as follows:\n",
    "\n",
    "![Tensor Model Visualization](tensor-model.png)\n",
    "\n",
    "Tensor model predicts `Yhat[i,j,k]` by multiplying all latent vectors together element-wise and then taking the sum along the latent dimension (figure omits the global mean).\n",
    "\n",
    "For tensors SMURFF implements a `SparseTensor` class. `SparseTensor` is a wrapper around a pandas `DataFrame` where each row stores the coordinate and the value of a known cell in the tensor. Specifically, the integer columns in the DataFrame give the coordinate of the cell and `float` (or double) column stores the value in the cell (the order of the columns does not matter). The coordinates are 0-based. The shape of the `SparseTensor` can be provided, otherwise it is inferred from the maximum index in each mode.\n",
    "\n",
    "Here is a simple toy example with factorizing a 3-tensor with side information on the first mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import smurff\n",
    "import itertools\n",
    "\n",
    "## generating toy data\n",
    "A = np.random.randn(15, 2)\n",
    "B = np.random.randn(3, 2)\n",
    "C = np.random.randn(2, 2)\n",
    "\n",
    "idx = list( itertools.product(np.arange(A.shape[0]),\n",
    "                              np.arange(B.shape[0]),\n",
    "                              np.arange(C.shape[0])) )\n",
    "df  = pd.DataFrame( np.asarray(idx), columns=[\"A\", \"B\", \"C\"])\n",
    "df[\"value\"] = np.array([ np.sum(A[i[0], :] * B[i[1], :] * C[i[2], :]) for i in idx ])\n",
    "\n",
    "## assigning 20% of the cells to test set\n",
    "Ytrain, Ytest = smurff.make_train_test_df(df, 0.2)\n",
    "\n",
    "print(\"Ytrain = \", Ytrain)\n",
    "\n",
    "## for artificial dataset using small values for burnin, nsamples and num_latents is fine\n",
    "predictions = smurff.BPMFSession(\n",
    "                        Ytrain=Ytrain,\n",
    "                        Ytest=Ytest,\n",
    "                        num_latent=4,\n",
    "                        burnin=20,\n",
    "                        nsamples=20).run()\n",
    "\n",
    "print(\"First prediction of Ytest tensor: \", predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
