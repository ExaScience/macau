{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare train, test and side-info\n",
    "\n",
    "We first need to download and prepare the data files. This can be acomplished using this a built-in function is smurff. IC50 is a compound x protein matrix, The ECFP matrix as features as side information on the compounds.\n",
    "\n",
    "We also load a notebook extension wurlitzer to make the output that would normally go to the terminal end up in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext wurlitzer\n",
    "import smurff\n",
    "\n",
    "ic50_train, ic50_test, ecfp = smurff.load_chembl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization without Side Information\n",
    "\n",
    "As a first example we can run SMURFF without side information. The method used here is BPMF.\n",
    "\n",
    "Input matrix for `Y` is a sparse scipy matrix (either coo_matrix, csr_matrix or csc_matrix). The test matrix\n",
    "`Ytest` also needs to ne sparse matrix of the same size as `Y`. Here we have used burn-in of 20 samples for the Gibbs sampler and then collected 80 samples from the model. We use 16 latent dimensions in the model.\n",
    "\n",
    "For good results you will need to run more sampling and burnin iterations (>= 1000) and maybe more latent dimensions.\n",
    "\n",
    "We create a session, and the `run` method returns the predictions of the `Ytest` matrix. `predictions` is a list of of type `Prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First prediction element:  (2036, 116): 6.33 | 1sample: 5.40 | avg: 5.08 | var: 196.66\n",
      "RMSE = 0.9068791038324626\n"
     ]
    }
   ],
   "source": [
    "session = smurff.BPMFSession(\n",
    "                       Ytrain     = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       num_latent = 16,\n",
    "                       burnin     = 20,\n",
    "                       nsamples   = 80,\n",
    "                       verbose    = 0,)\n",
    "\n",
    "predictions = session.run()\n",
    "print(\"First prediction element: \", predictions[0])\n",
    "\n",
    "rmse = smurff.calc_rmse(predictions)\n",
    "print(\"RMSE =\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization with Side Information\n",
    "\n",
    "If we want to use the compound features we can use the Macau algorithm.\n",
    "\n",
    "The parameter `side_info = [ecfp, None]` sets the side information for rows and columns, respectively. In this example we only use side information for the compounds (rows of the matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No threading library used.\n",
      "PythonSession {\n",
      "  Data: {\n",
      "    Type: ScarceMatrixData [with NAs]\n",
      "    Component-wise mean: 6.4\n",
      "    Component-wise variance: 1.9\n",
      "    Noise: Fixed gaussian noise with precision: 5.00\n",
      "    Size: 47424 [15073 x 346] (0.91%)\n",
      "      Warning: 67 empty rows\n",
      "      Warning: 2 empty cols\n",
      "  }\n",
      "  Model: {\n",
      "    Num-latents: 16\n",
      "  }\n",
      "  Priors: {\n",
      "    0: MacauPrior\n",
      "     SideInfo: SparseDouble [15073, 105672]\n",
      "     Method: CG Solver\n",
      "     Tol: 0.00\n",
      "     BetaPrecision: 5.00\n",
      "    1: NormalPrior\n",
      "  }\n",
      "  Result: {\n",
      "    Test data: 11856 [15073 x 346] (0.23%)\n",
      "  }\n",
      "  Version: v0.12.0-10-g41ee78f\n",
      "  Iterations: 40 burnin + 100 samples\n",
      "  Save model: never\n",
      "}\n",
      " ====== Initial phase ====== \n",
      "Initial   0/  0: RMSE: nan (1samp: nan)  U:[0.00e+00, 0.00e+00] [took: 0.0s]\n",
      " ====== Sampling (burning phase) ====== \n",
      "Burnin   1/ 40: RMSE: nan (1samp: 6.6903)  U:[1.55e+02, 1.15e+02] [took: 9.5s]\n",
      "Burnin   2/ 40: RMSE: nan (1samp: 4.0501)  U:[1.95e+02, 1.48e+02] [took: 8.7s]\n",
      "Burnin   3/ 40: RMSE: nan (1samp: 3.0058)  U:[2.05e+02, 1.52e+02] [took: 8.8s]\n",
      "Burnin   4/ 40: RMSE: nan (1samp: 2.6122)  U:[2.11e+02, 1.52e+02] [took: 8.7s]\n",
      "Burnin   5/ 40: RMSE: nan (1samp: 2.3774)  U:[2.15e+02, 1.51e+02] [took: 8.9s]\n",
      "Burnin   6/ 40: RMSE: nan (1samp: 2.2164)  U:[2.18e+02, 1.47e+02] [took: 8.6s]\n",
      "Burnin   7/ 40: RMSE: nan (1samp: 2.0666)  U:[2.20e+02, 1.48e+02] [took: 8.9s]\n",
      "Burnin   8/ 40: RMSE: nan (1samp: 1.9850)  U:[2.22e+02, 1.46e+02] [took: 8.6s]\n",
      "Burnin   9/ 40: RMSE: nan (1samp: 1.9037)  U:[2.24e+02, 1.44e+02] [took: 8.9s]\n",
      "Burnin  10/ 40: RMSE: nan (1samp: 1.8599)  U:[2.26e+02, 1.42e+02] [took: 8.5s]\n",
      "Burnin  11/ 40: RMSE: nan (1samp: 1.7989)  U:[2.27e+02, 1.40e+02] [took: 8.8s]\n",
      "Burnin  12/ 40: RMSE: nan (1samp: 1.7683)  U:[2.29e+02, 1.38e+02] [took: 9.2s]\n",
      "[Received Ctrl-C. Stopping after finishing the current iteration.]\n",
      "Burnin  13/ 40: RMSE: nan (1samp: 1.7351)  U:[2.30e+02, 1.36e+02] [took: 8.6s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1891a1ea3ca9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                        \u001b[0mnum_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                        \u001b[0mburnin\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                        nsamples   = 100).run()\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msmurff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mwrapper.pyx\u001b[0m in \u001b[0;36msmurff.wrapper.TrainSession.run\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mwrapper.pyx\u001b[0m in \u001b[0;36msmurff.wrapper.TrainSession.step\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = smurff.MacauSession(\n",
    "                       Ytrain     = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       side_info  = [ecfp, None],\n",
    "                       num_latent = 16,\n",
    "                       burnin     = 40,\n",
    "                       nsamples   = 100).run()\n",
    "\n",
    "smurff.calc_rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate sampler\n",
    "\n",
    "SMURFF also includes an option to use a `very fast` univariate sampler, i.e., instead of sampling blocks of variables jointly it samples each individually. An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = smurff.MacauSession(\n",
    "                       Ytrain     = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       side_info  = [ecfp, None],\n",
    "                       univariate = True,\n",
    "                       num_latent = 32,\n",
    "                       burnin     = 500,\n",
    "                       nsamples   = 3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using it we recommend using larger values for `burnin` and `nsamples`, because the univariate sampler mixes slower than the blocked sampler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive noise\n",
    "\n",
    "In the previous examples we fixed the observation noise by specifying `precision = 5.0`. Instead we can also allow the model to automatically determine the precision of the noise by setting signal-to-noise ratio parameters `sn_init` and `sn_max`.\n",
    "\n",
    "`sn_init` is an initial signal-to-noise ratio.\n",
    "\n",
    "`sn_max`  is the maximum allowed signal-to-noise ratio. This means that if the updated precision would imply a higher signal-to-noise ratio than `sn_max`, then the precision value is set to `(sn_max + 1.0) / Yvar` where `Yvar` is the variance of the training dataset `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = smurff.smurff(Y          = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       priors     = ['macauone', 'normal'],\n",
    "                       side_info  = [ecfp, None],\n",
    "                       aux_data   = [[], []],\n",
    "                       num_latent = 32,\n",
    "                       sn_init    = 0,\n",
    "                       sn_max     = 1,\n",
    "                       burnin     = 500,\n",
    "                       nsamples   = 3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binary matrices\n",
    "\n",
    "SMURFF can also factorize binary matrices (with or without side information). As an input the sparse matrix should only contain values of 0 or 1. To factorize them we employ probit noise model that can be enabled by setting `threshold` parameter.\n",
    "\n",
    "Care has to be taken to make input to the model, as operating with sparse matrices can drop real 0 measurements. In the below example, we first copy the matrix (line 9) and then threshold the data to binary (line 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using activity threshold pIC50 > 6.5\n",
    "act = ic50\n",
    "act.data = act.data > 6.5\n",
    "act_train, act_test = smurff.make_train_test(act, 0.5)\n",
    "\n",
    "## running factorization (Macau)\n",
    "result = smurff.smurff(Y          = act_train,\n",
    "                       Ytest      = act_test,\n",
    "                       priors     = ['macau', 'normal'],\n",
    "                       side_info  = [ecfp, None],\n",
    "                       aux_data   = [[], []],\n",
    "                       num_latent = 32,\n",
    "                       threshold  = 0.5,\n",
    "                       burnin     = 500,\n",
    "                       nsamples   = 3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tensor Factorization\n",
    "\n",
    "SMURFF also supports tensor factorization with and without side information on any of the modes. Tensor can be thought as generalization of matrix to relations with more than two items. For example 3-tensor of `drug x cell x gene` could express the effect of a drug on the given cell and gene. In this case the prediction for the element `Yhat[i,j,k]`* is given by\n",
    "\n",
    "$$ \\hat{Y}_{ijk} = \\sum_{d=1}^{D}u^{(1)}_{d,i}u^{(2)}_{d,j}u^{(3)}_{d,k} + mean $$\n",
    "\n",
    "Visually the model can be represented as follows:\n",
    "\n",
    "<img src=\"https://macau.readthedocs.io/en/latest/_images/tensor-model.png\" alt=\"tesor-model\" style=\"width: 50%; height: 50%\"/>\n",
    "<center><i>Tensor model predicts <strong><code>Yhat[i,j,k]</code></strong> by multiplying all latent vectors together element-wise and then taking the sum along the latent dimension (figure omits the global mean).</i></center>\n",
    "\n",
    "For tensors SMURFF packages uses Pandas `DataFrame` where each row stores the coordinate and the value of a known cell in the tensor. Specifically, the integer columns in the DataFrame give the coordinate of the cell and `float` (or double) column stores the value in the cell (the order of the columns does not matter). The coordinates are 0-based.\n",
    "\n",
    "Here is a simple toy example with factorizing a 3-tensor with side information on the first mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import smurff\n",
    "import itertools\n",
    "\n",
    "## generating toy data\n",
    "A = np.random.randn(15, 2)\n",
    "B = np.random.randn(3, 2)\n",
    "C = np.random.randn(2, 2)\n",
    "\n",
    "idx = list( itertools.product(np.arange(A.shape[0]),\n",
    "                              np.arange(B.shape[0]),\n",
    "                              np.arange(C.shape[0])) )\n",
    "df  = pd.DataFrame( np.asarray(idx), columns=[\"A\", \"B\", \"C\"])\n",
    "df[\"value\"] = np.array([ np.sum(A[i[0], :] * B[i[1], :] * C[i[2], :]) for i in idx ])\n",
    "\n",
    "## assigning 20% of the cells to test set\n",
    "Ytrain, Ytest = smurff.make_train_test_df(df, 0.2)\n",
    "\n",
    "## for artificial dataset using small values for burnin, nsamples and num_latents is fine\n",
    "results = smurff.smurff(Ytrain,\n",
    "                        Ytest=Ytest,\n",
    "                        priors=['normal', 'normal', 'normal'],\n",
    "                        side_info=[None, None, None],\n",
    "                        aux_data=[[], [], []],\n",
    "                        num_latent=4,\n",
    "                        precision=50,\n",
    "                        burnin=20,\n",
    "                        nsamples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
