{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with SMURFF\n",
    "\n",
    "In this notebook we will continue on the first example. After running a training trainSession again in SMURFF, we will look deeper into how to use SMURFF for making predictions. The full Python API for predictions is available in [Python API Reference » Inference](../api/inference.html).\n",
    "\n",
    "To make predictions we recall that the value of a tensor model is given by a tensor contraction of all latent matrices. Specifically, the prediction for the element $\\hat{Y}_{ijk}$ of a rank-3 tensor is given by\n",
    "\n",
    "$$   \\hat{Y}_{ijk} = \\sum_{d=1}^D u^{(1)}_{d,i} u^{(2)}_{d,j} u^{(3)}_{d,k} + mean $$\n",
    "\n",
    "Since a matrix is a rank-2 tensor the prediction for a matrix is given by:\n",
    "\n",
    "$$   \\hat{Y}_{ij} = \\sum_{d=1}^D u^{(1)}_{d,i} u^{(2)}_{d,j} + mean $$\n",
    "\n",
    "These inner products are computed by SMURFF automagicaly, as we will see below.\n",
    "\n",
    "### Saving models\n",
    "\n",
    "We run a `Macau` training trainSession using side information (`ecfp`) from the chembl dataset.\n",
    "We make sure we *save every 10th sample*, such that we can load the model afterwards. This run will take some minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smurff\n",
    "import os\n",
    "import logging\n",
    "\n",
    "ic50_train, ic50_test, ecfp = smurff.load_chembl()\n",
    "\n",
    "# limit to 100 rows and 100 features to make thinks go faster\n",
    "ic50_train = ic50_train.tocsr()[:100,:]\n",
    "ic50_test = ic50_test.tocsr()[:100,:]\n",
    "ecfp = ecfp.tocsr()[:100,:].tocsc()[:,:100]\n",
    "\n",
    "trainSession = smurff.MacauSession(\n",
    "                       Ytrain     = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       side_info  = [ecfp, None],\n",
    "                       num_latent = 16,\n",
    "                       burnin     = 200,\n",
    "                       nsamples   = 100,\n",
    "                       save_freq  = 10,\n",
    "                       save_name  = \"ic50-macau.hdf5\",\n",
    "                       verbose    = 0,)\n",
    "\n",
    "predictions = trainSession.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved Model\n",
    "\n",
    "The model is saved in an HDF5 file, in this case `ic50-macau.hdf5`.\n",
    "The file contains all saved info from this training run. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "h5ls -r ic50-macau.hdf5 | head -n 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the HDF5 file is:\n",
    "\n",
    "- Datasets in `/config` contain the input data and configuration provided to the `TrainSession`\n",
    "- The different `/sample_*` datasets contain for each posterior sample:\n",
    "  - Predictions for the provided test matrix:\n",
    "    - `predictions/pred_1sample`: Predictions from this sample\n",
    "    - `predictions/pred_avg`: Predictions average across this and all previous samples\n",
    "    - `predictions/pred_var`: Predictions variance across this and all previous samples\n",
    "  - `latents_*`: Latent samples for each dimension\n",
    "  - `link_matrices/`: When sideinfo is used with the `MacauPrior`, this HDF5 group contains the ß link \n",
    "     matrix, and the µ HyperPrior sample. This will allow to make predictions from unseen sideinfo.\n",
    "\n",
    "Sparse matrices and tensors are stored using the [h5sparse-tensor Python package](https://pypi.org/project/h5sparse-tensor/) which is automatically installed as a dependency of smurff.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making  predictions from a `TrainSession`\n",
    "\n",
    "The easiest way to make predictions is from an existing `TrainSession`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = trainSession.makePredictSession()\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once we have a `PredictSession`, there are serveral ways to make predictions:\n",
    "\n",
    " * From a sparse matrix\n",
    " * For all possible elements in the matrix (the complete $U \\times V$)\n",
    " * For a single point in the matrix\n",
    " * Using only side-information\n",
    " \n",
    "#### Predict all elements\n",
    "\n",
    "We can make predictions for all rows $\\times$ columns in our matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictor.predict_all()\n",
    "print(len(p)) # p is a list of numpy arrays of size num samples, \n",
    "print(p[0].shape) # each array's shape = (num rows) x (num columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict element in a sparse matrix\n",
    "We can make predictions for a sparse matrix, for example our `ic50_test` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictor.predict_sparse(ic50_test)\n",
    "# p is a list of samples\n",
    "print(len(p),\" samples\") \n",
    "# each sample contains a sparse matrix with predictions for this sample\n",
    "print(\"predictions 1:\", type(p[0]), p[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict just one element\n",
    "\n",
    "Or just one element. Let's predict the first element of our `ic50_test` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import find\n",
    "import numpy as np\n",
    "\n",
    "(i,j,v) = find(ic50_test)\n",
    "predictions = predictor.predict((i[0],j[0]))\n",
    "print(predictions) # list of N samples, each sample is an array each containing a single prediction\n",
    "predictions = [ p.item() for p in predictions]\n",
    "print(\"as a list of floats:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the histogram of predictions for this element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a histogram of the samples.\n",
    "plt.subplot(111)\n",
    "plt.hist(predictions, bins=10, density=True, label = \"predictions's histogram\")\n",
    "plt.plot(v[0], 1., 'ro', markersize =5, label = 'actual value')\n",
    "plt.legend()\n",
    "plt.title('Histogram of ' + str(len(predictions)) + ' predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions using side information\n",
    "\n",
    "We can make predictions for rows/columns not in our train matrix, using only side info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import find\n",
    "\n",
    "(i,j,v) = find(ic50_test)\n",
    "row_side_info = ecfp.tocsr().getrow(i[0])\n",
    "p = predictor.predict((row_side_info,j[0]))\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to provide sideinfo for the columns, if the `MacauPrior` was used for the columns. See [smurff.PredictSession.predict](../api/inference.html#smurff.PredictSession.predict) for the full documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions from saved run\n",
    "\n",
    "One can also make a `PredictSession` from a saved HDF5 file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smurff\n",
    "\n",
    "predictor = smurff.PredictSession(\"ic50-macau.hdf5\")\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
