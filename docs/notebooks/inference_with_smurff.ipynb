{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference with SMURFF\n",
    "\n",
    "In this notebook we will continue on the first example. After running a training session again in SMURFF, we will look deeper into how to use SMURFF for making predictions.\n",
    "\n",
    "### Saving models\n",
    "\n",
    "We run a `Macau` training session using side information (`ecfp`) from the chembl dataset.\n",
    "We make sure we *save every 10th sample*, such that we can load the model afterwards. This run will take some minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smurff\n",
    "\n",
    "ic50_train, ic50_test, ecfp = smurff.load_chembl()\n",
    "\n",
    "session = smurff.MacauSession(\n",
    "                       Ytrain     = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       side_info  = [ecfp, None],\n",
    "                       num_latent = 16,\n",
    "                       burnin     = 200,\n",
    "                       nsamples   = 10,\n",
    "                       save_freq  = 1,\n",
    "                    \n",
    "                       save_prefix= \"ic50-macau/save\",\n",
    "                       verbose    = 1,)\n",
    "\n",
    "predictions = session.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saved files\n",
    "\n",
    "The saved files are indexed in a root ini-file, in this case the root ini-file will be `ic50-save-root.ini`.\n",
    "The content of this file lists all saved info for this training run. For example\n",
    "\n",
    "```ini\n",
    "options = ic50-save-options.ini\n",
    "sample_step_10 = ic50-save-sample-10-step.ini\n",
    "sample_step_20 = ic50-save-sample-20-step.ini\n",
    "sample_step_30 = ic50-save-sample-30-step.ini\n",
    "sample_step_40 = ic50-save-sample-40-step.ini\n",
    "```\n",
    "\n",
    "Each step ini-file contains the matrices saved in the step:\n",
    "\n",
    "```ini\n",
    "#models\n",
    "num_models = 2\n",
    "model_0 = ic50-save-sample-50-U0-latents.ddm\n",
    "model_1 = ic50-save-sample-50-U1-latents.ddm\n",
    "#predictions\n",
    "pred = ic50-save-sample-50-predictions.csv\n",
    "pred_state = ic50-save-sample-50-predictions-state.ini\n",
    "#priors\n",
    "num_priors = 2\n",
    "prior_0 = ic50-save-sample-50-F0-link.ddm\n",
    "prior_1 = ic50-save-sample-50-F1-link.ddm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making  predictions from a `TrainSession`\n",
    "\n",
    "The easiest way to make predictions is from an existing `TrainSession`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = session.makePredictSession()\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once we have a `PredictSession`, there are serveral ways to make predictions:\n",
    "\n",
    " * From a sparse matrix\n",
    " * For all possible elements in the matrix (the complete $U \\times V$)\n",
    " * For a single point in the matrix\n",
    " * Using only side-information\n",
    " \n",
    "#### Predict all elements\n",
    "\n",
    "We can make predictions for all rows $\\times$ columns in our matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictor.predict_all()\n",
    "print(p.shape) # p is a numpy array of size: (num samples) x (num rows) x (num columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict element in a sparse matrix\n",
    "We can make predictions for a sparse matrix, for example our `ic50_test` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = predictor.predict_some(ic50_test)\n",
    "print(len(p),\"predictions\") # p is a list of Predictions\n",
    "print(\"predictions 1:\", p[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict just one element\n",
    "\n",
    "Or just one element. Let's predict the first element of our `ic50_test` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import find\n",
    "(i,j,v) = find(ic50_test)\n",
    "p = predictor.predict_one((i[0],j[0]),v[0])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the histogram of predictions for this element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a histogram of the samples.\n",
    "plt.subplot(111)\n",
    "plt.hist(p.pred_all, bins=10, density=True, label = \"predictions's histogram\")\n",
    "plt.plot(p.val, 1., 'ro', markersize =5, label = 'actual value')\n",
    "plt.legend()\n",
    "plt.title('Histogram of ' + str(len(p.pred_all)) + ' predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions using side information\n",
    "\n",
    "We can make predictions for rows/columns not in our train matrix, using only side info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import find\n",
    "\n",
    "(i,j,v) = find(ic50_test)\n",
    "row_side_info = ecfp.tocsr().getrow(i[0])\n",
    "beta = predictor.samples[0].betas[0]\n",
    "uhat = row_side_info.dot(beta.transpose())\n",
    "print(\"side = \", row_side_info.shape)\n",
    "print(\"uhat = \", uhat.shape)\n",
    "uhat_squeezed = np.squeeze(uhat) \n",
    "print(\"uhat squeezed = \", uhat_squeezed.shape)\n",
    "p = predictor.predict_one((row_side_info,j[0]),v[0])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the saved model itself\n",
    "\n",
    "The latents matrices for all samples are stored in the `PredictSession` as `numpy` arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the U matrices for all samples\n",
    "for i,s in enumerate(predictor.samples):\n",
    "    print(\"sample\", i, \":\", [ (m, u.shape) for m,u in enumerate(s.latents) ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions from saved run\n",
    "\n",
    "One can also make a `PredictSession` from a save root ini-file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smurff\n",
    "\n",
    "predictor = smurff.PredictSession.fromRootFile(\"ic50-macau-save-root.ini\")\n",
    "print(predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
