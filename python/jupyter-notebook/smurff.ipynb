{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMURFF Tutorial\n",
    "\n",
    "In these examples we use ChEMBL dataset for compound-proteins activities (IC50). The IC50 values and ECFP fingerprints can be downloaded from these two urls:\n",
    "\n",
    "`\n",
    "wget http://homes.esat.kuleuven.be/~jsimm/chembl-IC50-346targets.mm\n",
    "wget http://homes.esat.kuleuven.be/~jsimm/chembl-IC50-compound-feat.mm\n",
    "`\n",
    "\n",
    "## Matrix Factorization Model\n",
    "\n",
    "The matrix factorization models cell **`Y[i,j]`** by the inner product of the latents\n",
    "\n",
    "$$ Y_{ij} âˆ¼ N(\\textbf{u}_{i} \\textbf{v}_{j} + mean, \\alpha^{-1}) $$\n",
    "\n",
    "where $\\textbf{u}_{i}$ and $\\textbf{v}_{j}$ are the latent vector for i-th row and j-th column, and $\\alpha$ is the precision of the observation noise. The model also uses a fixed global mean for the whole matrix.\n",
    "\n",
    "## Matrix Factorization with Side Information\n",
    "\n",
    "In this example we use MCMC (Gibbs) sampling to perform factorization of the compound x protein IC50 matrix by using ECFP features as side information on the compounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smurff\n",
    "import scipy.io\n",
    "\n",
    "import scipy.sparse\n",
    "import numpy\n",
    "\n",
    "## loading data\n",
    "ic50 = scipy.io.mmread(\"chembl-IC50-346targets.mm\")\n",
    "ecfp = scipy.io.mmread(\"chembl-IC50-compound-feat.mm\")\n",
    "\n",
    "## creating train and test sets\n",
    "ic50_train, ic50_test = smurff.make_train_test(ic50, 0.2)\n",
    "\n",
    "ic50 = scipy.sparse.rand(10, 20, 0.2)\n",
    "ic50_train, ic50_test = smurff.make_train_test(ic50, 0.5)\n",
    "ecfp = scipy.sparse.coo_matrix( numpy.random.rand(10, 2) )\n",
    "\n",
    "## running factorization (Macau)\n",
    "result = smurff.smurff(Y            = ic50_train,\n",
    "                       Ynoise       = ('fixed', 5.0, None, None, None),\n",
    "                       Ytest        = ic50_test,\n",
    "                       priors       = ['macau', 'normal'],\n",
    "                       side_info  = [ecfp, None],\n",
    "                       aux_data   = [[], []],\n",
    "                       num_latent = 32,\n",
    "                       burnin     = 400,\n",
    "                       nsamples   = 1600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input matrix for **`Y`** is a sparse scipy matrix (either coo_matrix, csr_matrix or csc_matrix).\n",
    "\n",
    "In this example, we have assigned 20% of the IC50 data to the test set by setting **`Ytest = 0.2`**. If you want to use a predefined test data, set **`Ytest = my_test_matrix`**, where the matrix is a sparse matrix of the same size as **`Y`**. Here we have used burn-in of 400 samples for the Gibbs sampler and then collected 1600 samples from the model. This is usually sufficient. For quick runs smaller numbers can be used, like **`burnin = 100, nsamples = 500`**.\n",
    "\n",
    "The parameter **`side_info = [ecfp, None]`** sets the side information for rows and columns, respectively. In this example we only use side information for the compounds (rows of the matrix).\n",
    "\n",
    "The **`precision = 5.0`** specifies the precision of the IC50 observations, i.e., 1 / variance.\n",
    "\n",
    "When the run has completed you can check the **`result`** object and its **`predictions`** field, which is a list of **`ResultItem`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3603859994129265\n",
      "(5, 9): 0.48548634258129886 | 1sample: 2.828677914937058 | avg: 0.43147450466238263 | var: 6356.653252811862 | stds: 1.9938387355982796\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE: {0}\".format(result.rmse))\n",
    "print(result.predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate sampler\n",
    "\n",
    "SMURFF also includes an option to use a **very fast** univariate sampler, i.e., instead of sampling blocks of variables jointly it samples each individually. An example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = smurff.smurff(Y          = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       priors     = ['macauone', 'normal'],\n",
    "                       side_info  = [ecfp, None],\n",
    "                       aux_data   = [[], []],\n",
    "                       num_latent = 32,\n",
    "                       burnin     = 500,\n",
    "                       nsamples   = 3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using it we recommend using larger values for **`burnin`** and **`nsamples`**, because the univariate sampler mixes slower than the blocked sampler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptive noise\n",
    "\n",
    "In the previous examples we fixed the observation noise by specifying **`precision = 5.0`**. Instead we can also allow the model to automatically determine the precision of the noise by setting signal-to-noise ratio parameters **`sn_init`** and **`sn_max`**.\n",
    "\n",
    "**`sn_init`** is an initial signal-to-noise ratio.\n",
    "\n",
    "**`sn_max`**  is the maximum allowed signal-to-noise ratio. This means that if the updated precision would imply a higher signal-to-noise ratio than **`sn_max`**, then the precision value is set to **`(sn_max + 1.0) / Yvar`** where **`Yvar`** is the variance of the training dataset **`Y`**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = smurff.smurff(Y          = ic50_train,\n",
    "                       Ynoise     = ('adaptive', None, 0, 1, None),\n",
    "                       Ytest      = ic50_test,\n",
    "                       priors     = ['macauone', 'normal'],\n",
    "                       side_info  = [ecfp, None],\n",
    "                       aux_data   = [[], []],\n",
    "                       num_latent = 32,\n",
    "                       burnin     = 500,\n",
    "                       nsamples   = 3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Binary matrices\n",
    "\n",
    "SMURFF can also factorize binary matrices (with or without side information). As an input the sparse matrix should only contain values of 0 or 1. To factorize them we employ probit noise model that can be enabled by setting **`threshold`** parameter.\n",
    "\n",
    "Care has to be taken to make input to the model, as operating with sparse matrices can drop real 0 measurements. In the below example, we first copy the matrix (line 9) and then threshold the data to binary (line 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using activity threshold pIC50 > 6.5\n",
    "act = ic50\n",
    "act.data = act.data > 6.5\n",
    "act_train, act_test = smurff.make_train_test(act, 0.5)\n",
    "\n",
    "## running factorization (Macau)\n",
    "result = smurff.smurff(Y          = act_train,\n",
    "                       Ynoise     = ('probit', None, None, None, 0.5),\n",
    "                       Ytest      = act_test,\n",
    "                       priors     = ['macau', 'normal'],\n",
    "                       side_info  = [ecfp, None],\n",
    "                       aux_data   = [[], []],\n",
    "                       num_latent = 32,\n",
    "                       burnin     = 500,\n",
    "                       nsamples   = 3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization without Side Information\n",
    "\n",
    "You can run SMURFF without side information. But you should use Bayesian Matrix Factorization (BPMF) instead of macau prior.\n",
    "\n",
    "So you should set all **`side_info`** values to **`None`** and update **`priors`** parameter to have only **`'normal'`** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = smurff.smurff(Y          = ic50_train,\n",
    "                       Ytest      = ic50_test,\n",
    "                       priors     = ['normal', 'normal'],\n",
    "                       side_info  = [None, None],\n",
    "                       aux_data   = [[], []],\n",
    "                       num_latent = 32,\n",
    "                       burnin     = 200,\n",
    "                       nsamples   = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Tensor Factorization\n",
    "\n",
    "SMURFF also supports tensor factorization with and without side information on any of the modes. Tensor can be thought as generalization of matrix to relations with more than two items. For example 3-tensor of **`drug x cell x gene`** could express the effect of a drug on the given cell and gene. In this case the prediction for the element **`Yhat[i,j,k]`*** is given by\n",
    "\n",
    "$$ \\hat{Y}_{ijk} = \\sum_{d=1}^{D}u^{(1)}_{d,i}u^{(2)}_{d,j}u^{(3)}_{d,k} + mean $$\n",
    "\n",
    "Visually the model can be represented as follows:\n",
    "\n",
    "<img src=\"https://macau.readthedocs.io/en/latest/_images/tensor-model.png\" alt=\"tesor-model\" style=\"width: 50%; height: 50%\"/>\n",
    "<center><i>Tensor model predicts <strong><code>Yhat[i,j,k]</code></strong> by multiplying all latent vectors together element-wise and then taking the sum along the latent dimension (figure omits the global mean).</i></center>\n",
    "\n",
    "For tensors SMURFF packages uses Pandas **`DataFrame`** where each row stores the coordinate and the value of a known cell in the tensor. Specifically, the integer columns in the DataFrame give the coordinate of the cell and **`float`** (or double) column stores the value in the cell (the order of the columns does not matter). The coordinates are 0-based.\n",
    "\n",
    "Here is a simple toy example with factorizing a 3-tensor with side information on the first mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import smurff\n",
    "import itertools\n",
    "\n",
    "## generating toy data\n",
    "A = np.random.randn(15, 2)\n",
    "B = np.random.randn(3, 2)\n",
    "C = np.random.randn(2, 2)\n",
    "\n",
    "idx = list( itertools.product(np.arange(A.shape[0]),\n",
    "                              np.arange(B.shape[0]),\n",
    "                              np.arange(C.shape[0])) )\n",
    "df  = pd.DataFrame( np.asarray(idx), columns=[\"A\", \"B\", \"C\"])\n",
    "df[\"value\"] = np.array([ np.sum(A[i[0], :] * B[i[1], :] * C[i[2], :]) for i in idx ])\n",
    "\n",
    "## assigning 20% of the cells to test set\n",
    "Ytrain, Ytest = smurff.make_train_test_df(df, 0.2)\n",
    "\n",
    "## for artificial dataset using small values for burnin, nsamples and num_latents is fine\n",
    "results = smurff.smurff(Ytrain,\n",
    "                        Ytest=Ytest,\n",
    "                        priors=['normal', 'normal', 'normal'],\n",
    "                        side_info=[None, None, None],\n",
    "                        aux_data=[[], [], []],\n",
    "                        num_latent=4,\n",
    "                        burnin=20,\n",
    "                        nsamples=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
